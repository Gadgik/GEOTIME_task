{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Загрузим пример данных\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Разделим на тренировочную и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Функция для генерации случайных параметров для CatBoost\n",
    "def random_catboost_params():\n",
    "    return {\n",
    "        'iterations': random.choice([100, 200, 300]),\n",
    "        'depth': random.choice([4, 6, 10]),\n",
    "        'learning_rate': random.choice([0.01, 0.1, 0.2]),\n",
    "    }\n",
    "\n",
    "# Создание списка моделей CatBoost с рандомными параметрами\n",
    "models = []\n",
    "for _ in range(5):  # например, 5 моделей CatBoost\n",
    "    params = random_catboost_params()\n",
    "    model = CatBoostClassifier(**params, verbose=0)\n",
    "    models.append(('catboost', model))\n",
    "\n",
    "# Создадим VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=models, voting='soft')\n",
    "\n",
    "# Обучение модели\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Прогнозирование\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# Оценка точности\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Загрузим пример данных\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Разделим на тренировочную и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Параметры для разных моделей CatBoost\n",
    "params_list = [\n",
    "    {'iterations': 100, 'depth': 4, 'learning_rate': 0.05, 'loss_function': 'MultiClass', 'verbose': 0},\n",
    "    {'iterations': 150, 'depth': 6, 'learning_rate': 0.1, 'loss_function': 'MultiClass', 'verbose': 0},\n",
    "    {'iterations': 200, 'depth': 8, 'learning_rate': 0.1, 'loss_function': 'MultiClass', 'verbose': 0},\n",
    "    {'iterations': 100, 'depth': 5, 'learning_rate': 0.2, 'loss_function': 'MultiClass', 'verbose': 0},\n",
    "    {'iterations': 250, 'depth': 7, 'learning_rate': 0.05, 'loss_function': 'MultiClass', 'verbose': 0}\n",
    "]\n",
    "\n",
    "# Создание списка моделей CatBoost с разными параметрами\n",
    "models = []\n",
    "for i, params in enumerate(params_list):\n",
    "    model = CatBoostClassifier(**params)\n",
    "    models.append((f'catboost_{i}', model))\n",
    "\n",
    "# Создадим VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=models, voting='soft')\n",
    "\n",
    "# Обучение модели\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Прогнозирование\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# Оценка точности\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('train.csv')  # Замените на ваш путь к данным\n",
    "\n",
    "# Предположим, что у вас есть признаки в колонках X и целевая переменная в y\n",
    "X = data.drop(columns=['target'])  # Замените на ваш набор признаков\n",
    "y = data['target']  # Замените на вашу целевую переменную\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Создание данных для LGBM\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "# Параметры модели\n",
    "params = {\n",
    "    'objective': 'binary',  # для бинарной классификации, для многоклассов можно использовать 'multiclass'\n",
    "    'metric': 'binary_error',  # метрика для бинарной классификации\n",
    "    'boosting_type': 'gbdt',  # тип бустинга\n",
    "    'num_leaves': 31,  # количество листьев\n",
    "    'learning_rate': 0.05,  # скорость обучения\n",
    "    'feature_fraction': 0.9  # случайный выбор признаков на каждом шаге\n",
    "}\n",
    "\n",
    "# Обучение модели\n",
    "bst = lgb.train(params, train_data, valid_sets=[test_data], early_stopping_rounds=10)\n",
    "\n",
    "# Прогнозирование\n",
    "y_pred = bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "\n",
    "# Преобразование вероятностей в метки классов\n",
    "y_pred_label = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Оценка качества модели\n",
    "accuracy = accuracy_score(y_test, y_pred_label)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('train.csv')  # Замените на ваш путь к данным\n",
    "\n",
    "# Предположим, что у вас есть признаки в колонках X и целевая переменная в y\n",
    "X = data.drop(columns=['target'])  # Замените на ваш набор признаков\n",
    "y = data['target']  # Замените на вашу целевую переменную\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Преобразование данных в формат DMatrix для XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Параметры модели\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # для бинарной классификации, для многоклассов используйте 'multi:softmax'\n",
    "    'eval_metric': 'logloss',  # метрика для бинарной классификации\n",
    "    'max_depth': 6,  # максимальная глубина дерева\n",
    "    'learning_rate': 0.05,  # скорость обучения\n",
    "    'subsample': 0.8,  # доля выборки для построения дерева\n",
    "    'colsample_bytree': 0.8  # доля признаков для каждого дерева\n",
    "}\n",
    "\n",
    "# Обучение модели\n",
    "num_round = 100  # количество итераций\n",
    "bst = xgb.train(params, dtrain, num_round, [(dtest, 'eval')], early_stopping_rounds=10)\n",
    "\n",
    "# Прогнозирование\n",
    "y_pred = bst.predict(dtest)\n",
    "\n",
    "# Преобразование вероятностей в метки классов\n",
    "y_pred_label = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Оценка качества модели\n",
    "accuracy = accuracy_score(y_test, y_pred_label)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRanker, Pool\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('train.csv')  # Замените на ваш путь к данным\n",
    "\n",
    "# Предположим, что у вас есть признаки в колонках X и целевая переменная в y\n",
    "X = data.drop(columns=['target', 'group_id'])  # Замените на ваш набор признаков\n",
    "y = data['target']  # Замените на вашу целевую переменную\n",
    "group = data['group_id']  # Предполагаем, что у вас есть колонка group_id для группы документов\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(X, y, group, test_size=0.2, random_state=42)\n",
    "\n",
    "# Создание Pool данных для CatBoost\n",
    "train_data = Pool(X_train, label=y_train, group_id=group_train)\n",
    "test_data = Pool(X_test, label=y_test, group_id=group_test)\n",
    "\n",
    "# Параметры модели CatBoost\n",
    "model = CatBoostRanker(iterations=1000, \n",
    "                       depth=6, \n",
    "                       learning_rate=0.05, \n",
    "                       loss_function='RMSE', \n",
    "                       custom_metric=['NDCG'], \n",
    "                       cat_features=[])\n",
    "\n",
    "# Обучение модели\n",
    "model.fit(train_data, eval_set=test_data, early_stopping_rounds=10)\n",
    "\n",
    "# Прогнозирование\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Оценка качества модели\n",
    "# Например, использование метрики NDCG для оценки качества ранга\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
